---
title: "Lab on Discrete Choice"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: false
      smooth_scroll: false
editor_options: 
  chunk_output_type: console
---

 1. consider estimation of demand model for transport
 2. look at IIA assumption (potential pitt-falls)
 3. extend with 3 types, check substitution patterns
 4. consider max-rank substitution

We consider here discrete choices over a set of alernatives. THe utility of the agent is modeled as 

# Discrete Choices

$$u_i(j) = \beta X_i + \epsilon_{ij}$$

and when the error term is type 2 extreme value:

$$F(\epsilon_{ij}) = \exp( -\exp( -\epsilon_{ij}  ) )$$

the choice probability is given by 

$$ Pr[j(i)^*=j] = \frac{ \exp[ u_i(j)  ] }{ \sum_j'  \exp[ u_i(j')  ]} $$

Armed with these tools we can tackle the data we are given.

## Data
```{r,message=FALSE}
library(AER)
library(mlogit)
library(kableExtra)
library(knitr)
library(foreach)
data("TravelMode")
data = TravelMode

kable(data[1:10,])
```

## Mlogit results

```{r,message=FALSE}
library(AER)
library(mlogit)
library(kableExtra)
library(knitr)
library(reshape2)
data("TravelMode")
TravelMode <- mlogit.data(TravelMode, choice = "choice", shape = "long", alt.var = "mode", chid.var = "individual")
data = TravelMode

## overall proportions for chosen mode
with(data, prop.table(table(mode[choice == TRUE])))

## travel vs. waiting time for different travel modes
ggplot(data,aes(x=wait, y=travel)) + geom_point() + facet_wrap(~mode)

## Greene (2003), Table 21.11, conditional logit model
fit1 <- mlogit(choice ~ gcost + wait, data = data, reflevel = "car")
# fit1 <- mlogit(choice ~ gcost + wait | income, data = data, reflevel = "car")
# fit1 <- mlogit(choice ~ gcost + wait + income, data = data, reflevel = "car") # why doesn't it work?
summary(fit1)

```

## Predict outcome when changing air price

We want to simulate the demand impact of a price increase for air-travel. And see how people will move from one option to another.


```{r}
data2 =copy(data)
I=paste(data2$mode)=="air"

# force other alternatives to mean value
for (mm in c('car','train','bus')) {
  data2$gcost[paste(data2$mode)==mm] = mean(data2$gcost[paste(data2$mode)==mm])
  data2$wait[paste(data2$mode)==mm]  = mean(data2$wait[paste(data2$mode)==mm])
}


# run a for lopp for different prices
# save shares for each option
rr = foreach(dprice = seq(-100,100,l=20), .combine = rbind)  %do% {
  data2$gcost[I] = data$gcost[I] + dprice
  res = colMeans(predict(fit1,newdata=data2))
  res['dprice'] = dprice
  res
} 

rr = melt(data.frame(rr),id.vars = "dprice")
ggplot(rr,aes(x=dprice,y=value,color=factor(variable))) + geom_line()
```

 - this does not include an overall participation margin
 - interesting fact that otherlines appear to move in parallel!

## IIA assumption

Due to the functional form for the multinomial logit, it is the case that the choice of car versus train is not affected by the price of air travel. 

This of-course goes away when including some randomness in the covariates and integrating over. Imagine the airline chooses to shift all realized prices, and we then take the average.

```{r}
data2 =copy(data)
I=paste(data2$mode)=="air"

rr = foreach(dprice = seq(-100,100,l=20), .combine = rbind)  %do% {
  data2$gcost[I] = data$gcost[I] + dprice
  res = colMeans(predict(fit1,newdata=data2))
  res['dprice'] = dprice
  res
} 

rr = melt(data.frame(rr),id.vars = "dprice")
ggplot(rr,aes(x=dprice,y=value,color=factor(variable))) + geom_line()

```

##  Nested logit

One way to test the assumption is to estimate without one alternative and see if it affects the parameters. For instance we can focus on whether `air` or `train` is chosen and estimate within.

```{r}
fit.nested <- mlogit(choice ~ wait + gcost, TravelMode, reflevel = "car",
           nests = list(fly = "air", ground = c("train", "bus", "car")),
           unscaled = TRUE)

summary(fit.nested)
```

```{r}
data2 =copy(data)
I=paste(data2$mode)=="bus"

# force other alternatives to mean value
for (mm in c('car','train','air')) {
  #data2$gcost[paste(data2$mode)==mm] = mean(data2$gcost[paste(data2$mode)==mm])
  data2$wait[paste(data2$mode)==mm]  = mean(data2$wait[paste(data2$mode)==mm])
}


# run a for lopp for different prices
# save shares for each option
rr = foreach(dprice = seq(-100,100,l=20), .combine = rbind)  %do% {
  data2$gcost[I] = data$gcost[I] + dprice
  res = colMeans(predict(fit.nested,newdata=data2))
  res['dprice'] = dprice
  res
} 

rr = melt(data.frame(rr),id.vars = "dprice")
ggplot(rr,aes(x=dprice,y=value,color=factor(variable))) + geom_line()
```

## Random coefficient model

Let's try with 2 groups of people to run an EM

```{r}
C = acast(data,individual ~ mode,value.var="choice")
C = C[,c(4,1,2,3)]
p1=0.5

I = sample(unique(data$individua),nrow(data)/8)
I  =data$individual %in% I

# we start with the very first mlogit (we randomly sub-sample to create some variation)
fit1 <- mlogit(choice ~ gcost , data = data[I,], reflevel = "car")
fit2 <- mlogit(choice ~ gcost , data = data[!I,], reflevel = "car")

liks = rep(0,15)
for (i in 1:15) {
  # for each individual we compute the posterior probability given their data
  p1v = predict(fit1,newdata=data)
  p2v = predict(fit2,newdata=data)
  
  p1v = rowSums(p1v * C)*p1
  p2v = rowSums(p2v * C)*(1-p1)
  
  liks[i] = sum(log(p1v+p2v))
  #cat(sprintf("ll=%f\n",ll))
  
  p1v  = p1v/(p1v+p2v)
  p1v  = as.numeric( p1v %x% c(1,1,1,1) )
  
  # finally we run the 2 mlogit with weights
  fit1 <- mlogit(choice ~ gcost , data = data,weights = p1v, reflevel = "car")
  fit2 <- mlogit(choice ~ gcost , data = data,weights = as.numeric(1-p1v), reflevel = "car")
  
  p1 = mean(p1v)
}
print(fit1)
print(fit2)
print(p1)
```

```{r}

plot(liks)

```

# Max rank estimator

```{r}
require(RcppSimpleTensor)
data("Train", package = "mlogit")
data = Train
fit = glm(choice=="choice1" ~ 0 + I(log(price1/price2)) + I(log(time1/time2)),data,family = binomial('probit'))
N = nrow(data)

ggplot(data,aes(x=log(price1/price2),y=log(time1/time2),color=choice)) + geom_point() + theme_bw()

# let's put this in matrices
X = cbind( log(data$price1/data$price2), log(data$time1/data$time2))
colnames(X) = c("price","time")
Y = (data$choice == "choice1")*1

t.tmp = tensorFunction(R[i] ~ I(VV[i]<VV[j])*I(Y[i]<Y[j]) + I(VV[i]>VV[j])*I(Y[i]>Y[j]))

# score function
score <- function(beta) {
  tot = 0; 
  VV = as.numeric(X %*% beta)
  tot = sum(t.tmp(VV,Y))
  return(data.frame(b1=beta[1],b2=beta[2],val=log(tot)))
}

rr =score(c(0.1,0.1))

require(foreach)
rr = data.table(foreach(b1 = seq(-5,-3,l=40),.combine=rbind) %:% 
                  foreach(b2 = seq(-3,-1,l=40),.combine=rbind) %do%
                  score(c(b1,b2)))

library(lattice)
wireframe(val~b1+b2,rr)

I = which.max(rr$val)
beta_hat = as.numeric(rr[I,c(b1,b2)])
beta     = as.numeric(fit$coefficients)

ggplot(rr,aes(x=b1,y=val,color=b2,group=b2)) + geom_line() +theme_bw() + 
  geom_vline(xintercept = beta[1],color="red",linetype=2) + 
  geom_vline(xintercept = beta_hat[1],color="blue",linetype=2)

ggplot(rr,aes(x=b2,y=val,color=b1,group=b1)) + geom_line() +theme_bw() + 
  geom_vline(xintercept = beta[2],color="red",linetype=2) + 
  geom_vline(xintercept = beta_hat[2],color="blue",linetype=2)

#fit2 <- mlogit(choice ~ price + time + change + comfort |-1, Tr)
```


Recovering the distribution of unbosverables:
```{r}
dd = data.table(Y=Y,R_hat= as.numeric(X%*%beta_hat))
g <- function(x0,h) dd[, sum( Y * dnorm( (R_hat-x0)/h))/sum( dnorm( (R_hat-x0)/h)) ]
h=0.3
dd = dd[, F_hat := g(R_hat,h),R_hat]

ggplot(dd,aes(x=R_hat,y=F_hat)) + geom_line(color="red")  + theme_bw() +  
  geom_line(aes(x=R_hat,y=plogis(R_hat)),color="blue",linetype=2) +
  geom_line(aes(x=R_hat,y=pnorm(R_hat)),color="green",linetype=2)

```


